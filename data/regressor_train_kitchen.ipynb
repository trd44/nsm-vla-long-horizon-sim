{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pickle\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_from_zip(zip_path):\n",
    "    \"\"\"\n",
    "    Load pickled data stored inside a .zip file created by TrajectoryRecorder.save_buffer.\n",
    "    \n",
    "    Args:\n",
    "        zip_path (str): Path to the .zip file.\n",
    "    \n",
    "    Returns:\n",
    "        object: The Python object that was originally pickled (list, dict, etc.).\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_file:\n",
    "        with zip_file.open('data.pkl', 'r') as file:\n",
    "            data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "def transform_to_list_of_images_dict(data):\n",
    "    # Takes a list of type [act1, obs1, act2, obs2, ...] with obs being a dict \"image_0\", \"image_1\", \"objects_pos\"\n",
    "    # Outputs a list of dict [obs1, obs2, ...] with obs being a dict {\"_agentview\":..., \"wrist_image\":...} \n",
    "    # image_0 is agentview, image_1 is wrist view\n",
    "    images_list = []\n",
    "    for episode in data:\n",
    "        obs_list = []\n",
    "        traj = episode[0]\n",
    "        #print(f\"Trajectory length: {traj}\")\n",
    "        for i in range(1, len(traj), 2):\n",
    "            obs = traj[i]\n",
    "            #print(obs[\"objects_pos\"][\"pot\"])\n",
    "            if obs is None:\n",
    "                continue\n",
    "            img_dict = {\"objects_pos\": obs[\"objects_pos\"].copy()}  # Copy the objects_pos dict\n",
    "            if \"image_0\" in obs:\n",
    "                image = obs[\"image_0\"]\n",
    "                image = cv2.flip(image.reshape(256, 256, 3), 0)\n",
    "                # Change the image to BGR\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                img_dict[\"agentview\"] = image\n",
    "            if \"image_1\" in obs:\n",
    "                image = obs[\"image_1\"]\n",
    "                image = cv2.flip(image.reshape(256, 256, 3), 0)\n",
    "                # Change the image to BGR\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                img_dict[\"wrist_image\"] = image\n",
    "            # # Display the images for debugging\n",
    "            # cv2.imshow(\"agentview\", img_dict[\"agentview\"])\n",
    "            # cv2.imshow(\"wrist_image\", img_dict[\"wrist_image\"])\n",
    "            # cv2.waitKey(1)\n",
    "            # print(img_dict[\"objects_pos\"][\"pot\"])\n",
    "            obs_list.append(img_dict)\n",
    "        images_list.append(obs_list)\n",
    "    return images_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo imports\n",
    "from ultralytics import YOLO\n",
    "from roboflow import Roboflow\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "import joblib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_episode_preds_and_ground_truth(episode, yolo_model):\n",
    "    info_list = []\n",
    "    for obs_step in episode:\n",
    "        info = {}\n",
    "        if \"agentview\" not in obs_step or \"wrist_image\" not in obs_step:\n",
    "            continue\n",
    "        agentview = obs_step[\"agentview\"]\n",
    "        wrist_image = obs_step[\"wrist_image\"]\n",
    "        # Get the predictions\n",
    "        agentview_results = yolo_model(agentview, verbose=False)[0]\n",
    "        wrist_results = yolo_model(wrist_image, verbose=False)[0]\n",
    "        # # display the image with bounding boxes\n",
    "        # displayed_image = agentview_results.plot()\n",
    "        # cv2.imshow('agentview', cv2.cvtColor(displayed_image, cv2.COLOR_RGB2BGR))\n",
    "        # cv2.waitKey(1)\n",
    "        # displayed_image = wrist_results.plot()\n",
    "        # cv2.imshow('wrist_image', cv2.cvtColor(displayed_image, cv2.COLOR_RGB2BGR))\n",
    "        # cv2.waitKey(1)\n",
    "        \n",
    "        #print(obs_step.keys())\n",
    "        objects_info = obs_step[\"objects_pos\"]  # dict with object names as keys and positions as values\n",
    "        for pred in agentview_results.boxes:\n",
    "            cls_id = int(pred.cls)\n",
    "            cls = yolo_model.names[cls_id]\n",
    "            x, y, w, h = pred.xywhn.tolist()[0]\n",
    "            conf = pred.conf\n",
    "            # Convert normalized coordinates to pixel coordinates\n",
    "            x = int(x * agentview.shape[1])\n",
    "            y = int(y * agentview.shape[0])\n",
    "            w = int(w * agentview.shape[1])\n",
    "            h = int(h * agentview.shape[0])\n",
    "\n",
    "            # Convert to pixel coordinates\n",
    "            x1, y1 = int(x - w / 2), int(y - h / 2)\n",
    "            x2, y2 = int(x + w / 2), int(y + h / 2)\n",
    "\n",
    "            # Get the ground truth position of the object\n",
    "            if cls in objects_info:\n",
    "                ground_truth_xyz = objects_info[cls]\n",
    "                ee_pos = objects_info[\"gripper\"]\n",
    "\n",
    "                found_match = False\n",
    "                for pred in wrist_results.boxes:\n",
    "                    cls_id2 = int(pred.cls)\n",
    "                    if cls_id2 == cls_id:\n",
    "                            found_match = True\n",
    "                            x_cam2, y_cam2, w_cam2, h_cam2 = pred.xywhn.tolist()[0]\n",
    "                            conf_cam2 = pred.conf\n",
    "                            # Convert normalized coordinates to pixel coordinates\n",
    "                            x_cam2 = int(x_cam2 * wrist_image.shape[1])\n",
    "                            y_cam2 = int(y_cam2 * wrist_image.shape[0])\n",
    "                            w_cam2 = int(w_cam2 * wrist_image.shape[1])\n",
    "                            h_cam2 = int(h_cam2 * wrist_image.shape[0])\n",
    "\n",
    "                            info = {\n",
    "                                \"px_cam1\": x,\n",
    "                                \"py_cam1\": y,\n",
    "                                \"w_cam1\": w,\n",
    "                                \"h_cam1\": h,\n",
    "                                \"conf_cam1\": float(conf),\n",
    "                                \"cls\": cls,\n",
    "                                \"px_cam2\": x_cam2,\n",
    "                                \"py_cam2\": y_cam2,\n",
    "                                \"w_cam2\": w_cam2,\n",
    "                                \"h_cam2\": h_cam2,\n",
    "                                \"conf_cam2\": float(conf_cam2),\n",
    "                                \"ee_x\": ee_pos[0] if ee_pos is not None else None,\n",
    "                                \"ee_y\": ee_pos[1] if ee_pos is not None else None,\n",
    "                                \"ee_z\": ee_pos[2] if ee_pos is not None else None,\n",
    "                                \"world_x\": ground_truth_xyz[0],\n",
    "                                \"world_y\": ground_truth_xyz[1],\n",
    "                                \"world_z\": ground_truth_xyz[2],\n",
    "                            }\n",
    "                if not found_match:\n",
    "                    x_cam2, y_cam2, w_cam2, h_cam2, conf_cam2 = 0, 0, 0, 0, 0\n",
    "                    info ={\n",
    "                        \"px_cam1\": x,\n",
    "                        \"py_cam1\": y,\n",
    "                        \"w_cam1\": w,\n",
    "                        \"h_cam1\": h,\n",
    "                        \"conf_cam1\": float(conf),\n",
    "                        \"cls\": cls,\n",
    "                        \"px_cam2\": 0,\n",
    "                        \"py_cam2\": 0,\n",
    "                        \"w_cam2\": 0,\n",
    "                        \"h_cam2\": 0,\n",
    "                        \"conf_cam2\": 0,\n",
    "                        \"ee_x\": ee_pos[0] if ee_pos is not None else None,\n",
    "                        \"ee_y\": ee_pos[1] if ee_pos is not None else None,\n",
    "                        \"ee_z\": ee_pos[2] if ee_pos is not None else None,\n",
    "                        \"world_x\": ground_truth_xyz[0],\n",
    "                        \"world_y\": ground_truth_xyz[1],\n",
    "                        \"world_z\": ground_truth_xyz[2],\n",
    "                        }\n",
    "            # if cls == \"pot\":    \n",
    "            #     print(ground_truth_xyz)\n",
    "            info_list.append(info)\n",
    "    return info_list\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m zip_path1 \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir1, zip_file1)\n\u001b[1;32m      9\u001b[0m zip_name1 \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(zip_file1)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 10\u001b[0m yolo_data1 \u001b[38;5;241m=\u001b[39m \u001b[43mload_from_zip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_path1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_file1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(yolo_data1)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m entries\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m yolo_data1 \u001b[38;5;241m=\u001b[39m transform_to_list_of_images_dict(yolo_data1)\n",
      "Cell \u001b[0;32mIn[1], line 19\u001b[0m, in \u001b[0;36mload_from_zip\u001b[0;34m(zip_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(zip_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m zip_file:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m zip_file\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m---> 19\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/lxm/lib/python3.8/zipfile.py:940\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[0;32m--> 940\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[1;32m    942\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readbuffer \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/anaconda3/envs/lxm/lib/python3.8/zipfile.py:1010\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1008\u001b[0m         data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read2(n \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(data))\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1010\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_type \u001b[38;5;241m==\u001b[39m ZIP_STORED:\n\u001b[1;32m   1013\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_left \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/lxm/lib/python3.8/zipfile.py:1040\u001b[0m, in \u001b[0;36mZipExtFile._read2\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1037\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMIN_READ_SIZE)\n\u001b[1;32m   1038\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_left)\n\u001b[0;32m-> 1040\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fileobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_left \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n",
      "File \u001b[0;32m~/anaconda3/envs/lxm/lib/python3.8/zipfile.py:764\u001b[0m, in \u001b[0;36m_SharedFile.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt read from the ZIP file while there \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    761\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis an open writing handle on it. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    762\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClose the writing handle before trying to read.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos)\n\u001b[0;32m--> 764\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a df that, for each label in the yolo model, gets the world_pos of the corresponding object as well as the ee_pos\n",
    "df_list1 = []\n",
    "# find all zip files in a directory\n",
    "yolo_model1 = YOLO(\"../PDDL/yolo_kitchen.pt\")\n",
    "data_dir1 = \"/home/lorangpi/CyclicLxM/data/KitchenEnv_seed_0/train_yolo/traces\"\n",
    "zip_files1 = [f for f in os.listdir(data_dir1) if f.endswith('reach_place.zip')]\n",
    "for zip_file1 in zip_files1:\n",
    "    zip_path1 = os.path.join(data_dir1, zip_file1)\n",
    "    zip_name1 = os.path.splitext(zip_file1)[0]\n",
    "    yolo_data1 = load_from_zip(zip_path1)\n",
    "    print(f\"Processing {zip_file1} with {len(yolo_data1)} entries\")\n",
    "    yolo_data1 = transform_to_list_of_images_dict(yolo_data1)\n",
    "    for episode_id1, episode1 in enumerate(yolo_data1):\n",
    "        print(f\"expisode {episode_id1} with {len(episode1)} steps\")\n",
    "        ep_info1 = get_episode_preds_and_ground_truth(episode1, yolo_model1)\n",
    "        # Display the first 10 yolo bounding boxes\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing reach_place.zip with 33 entries\n",
      "expisode 0 with 255 steps\n",
      "expisode 1 with 250 steps\n",
      "expisode 2 with 255 steps\n",
      "expisode 3 with 254 steps\n",
      "expisode 4 with 251 steps\n",
      "expisode 5 with 254 steps\n",
      "expisode 6 with 255 steps\n",
      "expisode 7 with 252 steps\n",
      "expisode 8 with 258 steps\n",
      "expisode 9 with 255 steps\n",
      "expisode 10 with 257 steps\n",
      "expisode 11 with 259 steps\n",
      "expisode 12 with 248 steps\n",
      "expisode 13 with 248 steps\n",
      "expisode 14 with 262 steps\n",
      "expisode 15 with 259 steps\n",
      "expisode 16 with 260 steps\n",
      "expisode 17 with 255 steps\n",
      "expisode 18 with 249 steps\n",
      "expisode 19 with 251 steps\n",
      "expisode 20 with 255 steps\n",
      "expisode 21 with 249 steps\n",
      "expisode 22 with 251 steps\n",
      "expisode 23 with 251 steps\n",
      "expisode 24 with 257 steps\n",
      "expisode 25 with 250 steps\n",
      "expisode 26 with 253 steps\n",
      "expisode 27 with 250 steps\n",
      "expisode 28 with 255 steps\n",
      "expisode 29 with 251 steps\n",
      "expisode 30 with 257 steps\n",
      "expisode 31 with 252 steps\n",
      "expisode 32 with 249 steps\n"
     ]
    }
   ],
   "source": [
    "# Create a df that, for each label in the yolo model, gets the world_pos of the corresponding object as well as the ee_pos\n",
    "df_list = []\n",
    "# find all zip files in a directory\n",
    "yolo_model = YOLO(\"../PDDL/yolo_kitchen.pt\")\n",
    "data_dir = \"/home/lorangpi/CyclicLxM/data/KitchenEnv_seed_0/train_yolo/traces/\"\n",
    "zip_files = [f for f in os.listdir(data_dir) if f.endswith('reach_place.zip')]\n",
    "for zip_file in zip_files:\n",
    "    zip_path = os.path.join(data_dir, zip_file)\n",
    "    zip_name = os.path.splitext(zip_file)[0]\n",
    "    videos_dir = os.path.join(data_dir, zip_name, 'videos')\n",
    "    os.makedirs(videos_dir, exist_ok=True)\n",
    "    yolo_data = load_from_zip(zip_path)\n",
    "    h264_videos_dir = os.path.join(videos_dir, 'h264')\n",
    "    os.makedirs(h264_videos_dir, exist_ok=True)\n",
    "    print(f\"Processing {zip_file} with {len(yolo_data)} entries\")\n",
    "    yolo_data = transform_to_list_of_images_dict(yolo_data)\n",
    "    for episode_id, episode in enumerate(yolo_data):\n",
    "        print(f\"expisode {episode_id} with {len(episode)} steps\")\n",
    "        ep_info = get_episode_preds_and_ground_truth(episode, yolo_model)\n",
    "        if len(ep_info) > 0:\n",
    "            df_list.extend(ep_info)\n",
    "        # if episode_id >= 10:\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>px_cam1</th>\n",
       "      <th>py_cam1</th>\n",
       "      <th>w_cam1</th>\n",
       "      <th>h_cam1</th>\n",
       "      <th>conf_cam1</th>\n",
       "      <th>cls</th>\n",
       "      <th>px_cam2</th>\n",
       "      <th>py_cam2</th>\n",
       "      <th>w_cam2</th>\n",
       "      <th>h_cam2</th>\n",
       "      <th>conf_cam2</th>\n",
       "      <th>ee_x</th>\n",
       "      <th>ee_y</th>\n",
       "      <th>ee_z</th>\n",
       "      <th>world_x</th>\n",
       "      <th>world_y</th>\n",
       "      <th>world_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>134</td>\n",
       "      <td>58</td>\n",
       "      <td>48</td>\n",
       "      <td>0.944306</td>\n",
       "      <td>pot</td>\n",
       "      <td>74</td>\n",
       "      <td>192</td>\n",
       "      <td>148</td>\n",
       "      <td>122</td>\n",
       "      <td>0.932665</td>\n",
       "      <td>-0.107792</td>\n",
       "      <td>-0.220290</td>\n",
       "      <td>0.943930</td>\n",
       "      <td>-0.119829</td>\n",
       "      <td>-0.159997</td>\n",
       "      <td>0.903693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>0.911553</td>\n",
       "      <td>bread</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.107792</td>\n",
       "      <td>-0.220290</td>\n",
       "      <td>0.943930</td>\n",
       "      <td>-0.375936</td>\n",
       "      <td>-0.162103</td>\n",
       "      <td>0.919784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68</td>\n",
       "      <td>134</td>\n",
       "      <td>58</td>\n",
       "      <td>48</td>\n",
       "      <td>0.944888</td>\n",
       "      <td>pot</td>\n",
       "      <td>73</td>\n",
       "      <td>193</td>\n",
       "      <td>145</td>\n",
       "      <td>124</td>\n",
       "      <td>0.940177</td>\n",
       "      <td>-0.108201</td>\n",
       "      <td>-0.220848</td>\n",
       "      <td>0.949371</td>\n",
       "      <td>-0.120193</td>\n",
       "      <td>-0.161145</td>\n",
       "      <td>0.906641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>0.911856</td>\n",
       "      <td>bread</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.108201</td>\n",
       "      <td>-0.220848</td>\n",
       "      <td>0.949371</td>\n",
       "      <td>-0.375936</td>\n",
       "      <td>-0.162103</td>\n",
       "      <td>0.919784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68</td>\n",
       "      <td>134</td>\n",
       "      <td>58</td>\n",
       "      <td>48</td>\n",
       "      <td>0.942343</td>\n",
       "      <td>pot</td>\n",
       "      <td>72</td>\n",
       "      <td>193</td>\n",
       "      <td>143</td>\n",
       "      <td>123</td>\n",
       "      <td>0.936066</td>\n",
       "      <td>-0.109140</td>\n",
       "      <td>-0.220597</td>\n",
       "      <td>0.955799</td>\n",
       "      <td>-0.121032</td>\n",
       "      <td>-0.162033</td>\n",
       "      <td>0.910119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   px_cam1  py_cam1  w_cam1  h_cam1  conf_cam1    cls  px_cam2  py_cam2  \\\n",
       "0       68      134      58      48   0.944306    pot       74      192   \n",
       "1       80       90      11      17   0.911553  bread        0        0   \n",
       "2       68      134      58      48   0.944888    pot       73      193   \n",
       "3       80       90      11      17   0.911856  bread        0        0   \n",
       "4       68      134      58      48   0.942343    pot       72      193   \n",
       "\n",
       "   w_cam2  h_cam2  conf_cam2      ee_x      ee_y      ee_z   world_x  \\\n",
       "0     148     122   0.932665 -0.107792 -0.220290  0.943930 -0.119829   \n",
       "1       0       0   0.000000 -0.107792 -0.220290  0.943930 -0.375936   \n",
       "2     145     124   0.940177 -0.108201 -0.220848  0.949371 -0.120193   \n",
       "3       0       0   0.000000 -0.108201 -0.220848  0.949371 -0.375936   \n",
       "4     143     123   0.936066 -0.109140 -0.220597  0.955799 -0.121032   \n",
       "\n",
       "    world_y   world_z  \n",
       "0 -0.159997  0.903693  \n",
       "1 -0.162103  0.919784  \n",
       "2 -0.161145  0.906641  \n",
       "3 -0.162103  0.919784  \n",
       "4 -0.162033  0.910119  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df_list)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bread', 'pot']\n"
     ]
    }
   ],
   "source": [
    "print(list(yolo_model.names.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'bread', 1: 'pot'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolo_model.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bread': 0, 'pot': 1}\n"
     ]
    }
   ],
   "source": [
    "#reverse the dict\n",
    "inv_class_dict = {v: k for k, v in yolo_model.names.items()}\n",
    "print(inv_class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>px_cam1</th>\n",
       "      <th>py_cam1</th>\n",
       "      <th>w_cam1</th>\n",
       "      <th>h_cam1</th>\n",
       "      <th>conf_cam1</th>\n",
       "      <th>cls</th>\n",
       "      <th>px_cam2</th>\n",
       "      <th>py_cam2</th>\n",
       "      <th>w_cam2</th>\n",
       "      <th>h_cam2</th>\n",
       "      <th>conf_cam2</th>\n",
       "      <th>ee_x</th>\n",
       "      <th>ee_y</th>\n",
       "      <th>ee_z</th>\n",
       "      <th>world_x</th>\n",
       "      <th>world_y</th>\n",
       "      <th>world_z</th>\n",
       "      <th>cls_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>134</td>\n",
       "      <td>58</td>\n",
       "      <td>48</td>\n",
       "      <td>0.944306</td>\n",
       "      <td>pot</td>\n",
       "      <td>74</td>\n",
       "      <td>192</td>\n",
       "      <td>148</td>\n",
       "      <td>122</td>\n",
       "      <td>0.932665</td>\n",
       "      <td>-0.107792</td>\n",
       "      <td>-0.220290</td>\n",
       "      <td>0.943930</td>\n",
       "      <td>-0.119829</td>\n",
       "      <td>-0.159997</td>\n",
       "      <td>0.903693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>0.911553</td>\n",
       "      <td>bread</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.107792</td>\n",
       "      <td>-0.220290</td>\n",
       "      <td>0.943930</td>\n",
       "      <td>-0.375936</td>\n",
       "      <td>-0.162103</td>\n",
       "      <td>0.919784</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68</td>\n",
       "      <td>134</td>\n",
       "      <td>58</td>\n",
       "      <td>48</td>\n",
       "      <td>0.944888</td>\n",
       "      <td>pot</td>\n",
       "      <td>73</td>\n",
       "      <td>193</td>\n",
       "      <td>145</td>\n",
       "      <td>124</td>\n",
       "      <td>0.940177</td>\n",
       "      <td>-0.108201</td>\n",
       "      <td>-0.220848</td>\n",
       "      <td>0.949371</td>\n",
       "      <td>-0.120193</td>\n",
       "      <td>-0.161145</td>\n",
       "      <td>0.906641</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>0.911856</td>\n",
       "      <td>bread</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.108201</td>\n",
       "      <td>-0.220848</td>\n",
       "      <td>0.949371</td>\n",
       "      <td>-0.375936</td>\n",
       "      <td>-0.162103</td>\n",
       "      <td>0.919784</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68</td>\n",
       "      <td>134</td>\n",
       "      <td>58</td>\n",
       "      <td>48</td>\n",
       "      <td>0.942343</td>\n",
       "      <td>pot</td>\n",
       "      <td>72</td>\n",
       "      <td>193</td>\n",
       "      <td>143</td>\n",
       "      <td>123</td>\n",
       "      <td>0.936066</td>\n",
       "      <td>-0.109140</td>\n",
       "      <td>-0.220597</td>\n",
       "      <td>0.955799</td>\n",
       "      <td>-0.121032</td>\n",
       "      <td>-0.162033</td>\n",
       "      <td>0.910119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   px_cam1  py_cam1  w_cam1  h_cam1  conf_cam1    cls  px_cam2  py_cam2  \\\n",
       "0       68      134      58      48   0.944306    pot       74      192   \n",
       "1       80       90      11      17   0.911553  bread        0        0   \n",
       "2       68      134      58      48   0.944888    pot       73      193   \n",
       "3       80       90      11      17   0.911856  bread        0        0   \n",
       "4       68      134      58      48   0.942343    pot       72      193   \n",
       "\n",
       "   w_cam2  h_cam2  conf_cam2      ee_x      ee_y      ee_z   world_x  \\\n",
       "0     148     122   0.932665 -0.107792 -0.220290  0.943930 -0.119829   \n",
       "1       0       0   0.000000 -0.107792 -0.220290  0.943930 -0.375936   \n",
       "2     145     124   0.940177 -0.108201 -0.220848  0.949371 -0.120193   \n",
       "3       0       0   0.000000 -0.108201 -0.220848  0.949371 -0.375936   \n",
       "4     143     123   0.936066 -0.109140 -0.220597  0.955799 -0.121032   \n",
       "\n",
       "    world_y   world_z  cls_id  \n",
       "0 -0.159997  0.903693       1  \n",
       "1 -0.162103  0.919784       0  \n",
       "2 -0.161145  0.906641       1  \n",
       "3 -0.162103  0.919784       0  \n",
       "4 -0.162033  0.910119       1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace cls names with the cls id from the yolo model\n",
    "df['cls_id'] = df['cls'].map(inv_class_dict)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16177"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.12079338838414694, -0.16070172883106865, 0.9046129247307965)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "X_dual = df[[\"cls_id\", \"px_cam1\", \"py_cam1\", \"w_cam1\", \"h_cam1\", \"conf_cam1\", \"px_cam2\", \"py_cam2\", \"w_cam2\", \"h_cam2\", \"conf_cam2\", \"ee_x\", \"ee_y\", \"ee_z\"]].values\n",
    "Y_dual = df[[\"world_x\", \"world_y\", \"world_z\"]].values\n",
    "\n",
    "reg_x_dual = GradientBoostingRegressor(n_estimators=200, max_depth=3, learning_rate=0.1)\n",
    "reg_y_dual = GradientBoostingRegressor(n_estimators=200, max_depth=3, learning_rate=0.1)\n",
    "reg_z_dual = GradientBoostingRegressor(n_estimators=200, max_depth=3, learning_rate=0.1)\n",
    "\n",
    "reg_x_dual.fit(X_dual, Y_dual[:, 0])\n",
    "reg_y_dual.fit(X_dual, Y_dual[:, 1])\n",
    "reg_z_dual.fit(X_dual, Y_dual[:, 2])\n",
    "def pixel_to_world_dual(cls, px1, py1, w1, h1, conf1, px2, py2, w2, h2, conf2, ee_x, ee_y, ee_z):\n",
    "    features = np.array([[cls, px1, py1, w1, h1, conf1, px2, py2, w2, h2, conf2, ee_x, ee_y, ee_z]])\n",
    "    x = reg_x_dual.predict(features)[0]\n",
    "    y = reg_y_dual.predict(features)[0]\n",
    "    z = reg_z_dual.predict(features)[0]\n",
    "    return x, y, z\n",
    "# --- Example usage ---\n",
    "# Get a prediction for the first row of the df dataframe\n",
    "cls = df.iloc[0][\"cls_id\"]\n",
    "px1, py1, w1, h1, conf1 = df.iloc[0][[\"px_cam1\", \"py_cam1\", \"w_cam1\", \"h_cam1\", \"conf_cam1\"]]\n",
    "px2, py2, w2, h2, conf2 = df.iloc[0][[\"px_cam2\", \"py_cam2\", \"w_cam2\", \"h_cam2\", \"conf_cam2\"]]\n",
    "ee_x, ee_y, ee_z = df.iloc[0][[\"ee_x\", \"ee_y\", \"ee_z\"]]\n",
    "print(pixel_to_world_dual(cls, px1, py1, w1, h1, conf1, px2, py2, w2, h2, conf2, ee_x, ee_y, ee_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kitchen_dual_cam_calibration_models.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the dual cam models\n",
    "joblib.dump({\"reg_x\": reg_x_dual, \"reg_y\": reg_y_dual, \"reg_z\": reg_z_dual}, \"kitchen_dual_cam_calibration_models.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error X: 4.226561474410599e-17, Std Error X: 0.0038526837356097714\n",
      "Mean Error Y: 1.2349918605507629e-17, Std Error Y: 0.0018548650474177726\n",
      "Mean Error Z: -1.2635418252070073e-16, Std Error Z: 0.0024229917013723163\n"
     ]
    }
   ],
   "source": [
    "# Replace pred columns with the dual cam predictions\n",
    "df[\"pred_x\"] = df.apply(lambda row: pixel_to_world_dual(row[\"cls_id\"], row[\"px_cam1\"], row[\"py_cam1\"], row[\"w_cam1\"], row[\"h_cam1\"], row[\"conf_cam1\"], row[\"px_cam2\"], row[\"py_cam2\"], row[\"w_cam2\"], row[\"h_cam2\"], row[\"conf_cam2\"], row[\"ee_x\"], row[\"ee_y\"], row[\"ee_z\"])[0], axis=1)\n",
    "df[\"pred_y\"] = df.apply(lambda row: pixel_to_world_dual(row[\"cls_id\"], row[\"px_cam1\"], row[\"py_cam1\"], row[\"w_cam1\"], row[\"h_cam1\"], row[\"conf_cam1\"], row[\"px_cam2\"], row[\"py_cam2\"], row[\"w_cam2\"], row[\"h_cam2\"], row[\"conf_cam2\"], row[\"ee_x\"], row[\"ee_y\"], row[\"ee_z\"])[1], axis=1)\n",
    "df[\"pred_z\"] = df.apply(lambda row: pixel_to_world_dual(row[\"cls_id\"], row[\"px_cam1\"], row[\"py_cam1\"], row[\"w_cam1\"], row[\"h_cam1\"], row[\"conf_cam1\"], row[\"px_cam2\"], row[\"py_cam2\"], row[\"w_cam2\"], row[\"h_cam2\"], row[\"conf_cam2\"], row[\"ee_x\"], row[\"ee_y\"], row[\"ee_z\"])[2], axis=1)\n",
    "\n",
    "# Compute the differences between the world and predicted positions\n",
    "df[\"diff_x\"] = df[\"world_x\"] - df[\"pred_x\"]\n",
    "df[\"diff_y\"] = df[\"world_y\"] - df[\"pred_y\"]\n",
    "df[\"diff_z\"] = df[\"world_z\"] - df[\"pred_z\"]\n",
    "\n",
    "# Compute the error metrics\n",
    "mean_error_x = df[\"diff_x\"].mean()\n",
    "mean_error_y = df[\"diff_y\"].mean()\n",
    "mean_error_z = df[\"diff_z\"].mean()\n",
    "std_error_x = df[\"diff_x\"].std()\n",
    "std_error_y = df[\"diff_y\"].std()\n",
    "std_error_z = df[\"diff_z\"].std()\n",
    "print(f\"Mean Error X: {mean_error_x}, Std Error X: {std_error_x}\")\n",
    "print(f\"Mean Error Y: {mean_error_y}, Std Error Y: {std_error_y}\")\n",
    "print(f\"Mean Error Z: {mean_error_z}, Std Error Z: {std_error_z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lxm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
